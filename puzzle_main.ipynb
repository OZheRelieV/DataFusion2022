{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5df8534",
   "metadata": {},
   "source": [
    "# \"Puzzle\" solution (DataFusion2022 track â„–2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb51b76",
   "metadata": {},
   "source": [
    "For the first let's check available resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e922954e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: 2\n",
      "RAM 15.5 Gb\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from psutil import virtual_memory\n",
    "\n",
    "print(f\"CPU: {multiprocessing.cpu_count()}\")\n",
    "print(f\"RAM {round(virtual_memory().total / 1024**3, 1)} Gb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb6d283",
   "metadata": {},
   "source": [
    "There are two main data files:\n",
    "\n",
    "- transactions.csv, that can be fully put into RAM;\n",
    "\n",
    "- clickstream.csv, that requires more RAM, than I have.\n",
    "\n",
    "That's why it was decided to provide an initial preprocessing. An initial preprocessing is splitting data files by 1_000_000 elements volume in each files and converting it into \".parquet\" extension.  \n",
    "So after it there are 20 files about transactions data and 127 click streaming service data.  \n",
    "In this notebook I'll use these files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8de0845",
   "metadata": {},
   "source": [
    "## 0 Importing necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6511b40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import trange\n",
    "from joblib import Parallel, delayed\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Initialising path for auxiliary files\n",
    "MAIN_PATH = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36367a37",
   "metadata": {},
   "source": [
    "Let's create necessary functions for:\n",
    "\n",
    "- feature engineering;\n",
    "- generating negative samples for matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c9f97e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_base_bank_features(data):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is intended for feature engineering of transactions data. Sum, mean and count features of\n",
    "    'currency_rk' are created taking in account all possible values of 'currency_rk'. Also sum, mean and\n",
    "    count features of combination 'currency_rk' and 'mcc_code' are created taking in account all possible\n",
    "    values of this pair.\n",
    "    The function produces data type changing aiming to reduce usable memory usage.\n",
    "    Input:\n",
    "    - data [pandas.DataFrame] - an initial data.\n",
    "    Output:\n",
    "    - data with new features [pandas.DataFrame].\n",
    "    \"\"\"\n",
    "    \n",
    "    pivot1 = data.pivot_table(index = 'user_id', values=['transaction_amt'],\n",
    "                              columns=['currency_rk'], aggfunc=['sum', 'mean', 'count']).fillna(0)\n",
    "    pivot1.columns = [f'{str(i[0])}-{str(i[2])}' for i in pivot1.columns]\n",
    "\n",
    "    pivot2 = data.pivot_table(index = 'user_id', values=['transaction_amt'],\n",
    "                              columns=['mcc_code', 'currency_rk'], aggfunc=['sum', 'mean', 'count']).fillna(0)\n",
    "    pivot2.columns = [f'{str(i[0])}-{str(i[2])}-{str(i[3])}' for i in pivot2.columns]\n",
    "\n",
    "    new_data = pivot1.join(pivot2)\n",
    "\n",
    "    dtypes = list()\n",
    "    for x in new_data.dtypes.tolist():\n",
    "        if x == 'int64':\n",
    "            dtypes.append('int16')\n",
    "        elif x == 'float64':\n",
    "            dtypes.append('float32')\n",
    "        else:\n",
    "            dtypes.append('object')\n",
    "\n",
    "    dtypes = dict(zip(new_data.columns.tolist(), dtypes))\n",
    "    new_data = new_data.astype(dtypes)\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0b12849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_base_rtk_features(data):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is intended for feature engineering of clickstream data. Count features of 'cat_id' are\n",
    "    created taking in account all possible values of 'cat_id'.\n",
    "    The function produces data type changing to an int type  aiming to reduce usable memory usage.\n",
    "    Input:\n",
    "    - data [pandas.DataFrame] - an initial data.\n",
    "    Output:\n",
    "    - data with new features [pandas.DataFrame].\n",
    "    \"\"\"\n",
    "    \n",
    "    new_data = data.pivot_table(index ='user_id', values=['timestamp'], columns=['cat_id'], aggfunc=['count']).fillna(0)\n",
    "    new_data.columns = [f'{str(i[0])}-{str(i[2])}' for i in new_data.columns]\n",
    "    \n",
    "    new_data = new_data.astype('int')\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15889fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hours_features(data, time_col: str, value_col: str, prefix: str):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is intended for creating features that contain information about produced operations\n",
    "    by hours.\n",
    "    The function produces data type changing to an int type aiming to reduce usable memory usage.\n",
    "    Input:\n",
    "    - data [pandas.DataFrame] - an initial data,\n",
    "    - time_col [str] - string representation of time column,\n",
    "    - value_col [str] - string representation of value column for pivot table,\n",
    "    -prefix [str] - string for naming features.\n",
    "    Output:\n",
    "    - data with new features [pandas.DataFrame].\n",
    "    \"\"\"\n",
    "    \n",
    "    data[time_col] = pd.to_datetime(data[time_col])\n",
    "    data['hour'] = data[time_col].dt.hour\n",
    "    \n",
    "    pivot_hours = pd.pivot_table(data, index='user_id', columns='hour', values=value_col, aggfunc='count').fillna(0)\n",
    "    pivot_hours['sum'] = pivot_hours.sum(axis=1)\n",
    "    \n",
    "    for i in pivot_hours.columns[:-1]:\n",
    "        \n",
    "        pivot_hours[i] /= pivot_hours['sum']\n",
    "        pivot_hours[i] = pivot_hours[i].astype('float32')\n",
    "        \n",
    "    pivot_hours.columns = [f'{prefix}_{str(i)}h' for i in pivot_hours.columns]\n",
    "    pivot_hours[f'{prefix}_sumh'] = pivot_hours[f'{prefix}_sumh'].astype('int')\n",
    "    \n",
    "    return pivot_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12ced6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_random_for_negative(x:str, k:int, list_of_uniq):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is intended for creating negative samples of macthing. Final collection doesn't\n",
    "    contain sample for which negatives are created.\n",
    "    Input:\n",
    "    - x [str] - string index of client,\n",
    "    - k [int] - integer number of negative samples per one positive sample,\n",
    "    - list_of_uniq [list / numpy.ndarray] - unique items of indexes\n",
    "    Ouput:\n",
    "     - collection that contains k negative samples per one positive sample [list / numpy.ndarray].\n",
    "    \"\"\"\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        final_list = np.random.choice(list_of_uniq, size=k, replace=False)\n",
    "        \n",
    "        if x not in final_list:\n",
    "            \n",
    "            return final_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17f376c",
   "metadata": {},
   "source": [
    "## 1 Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad3daae",
   "metadata": {},
   "source": [
    "Let's load train data about matching of bank clients and clickstreaming service clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9374c74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (17581, 2)\n",
      "Wall time: 160 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>rtk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8253</th>\n",
       "      <td>6783adb24efc43549038a0c037c958e7</td>\n",
       "      <td>036395725c6a4454bbabdcbca9e299f2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>ed1ab56022944a8b8c5799929ef85e32</td>\n",
       "      <td>543f9e92c965432e9fe04220bfa46e3b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8256</th>\n",
       "      <td>43cfd421f06343a5ae5ab1c07b442031</td>\n",
       "      <td>da8ecc0632664c9f8e7935a7d4fbdebd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4207</th>\n",
       "      <td>0f9b40ccb74a43aba8017ae10f0c54e1</td>\n",
       "      <td>113d266f48df4eb5a6d455cf153661ef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10151</th>\n",
       "      <td>1a5a3b9697bb45d78f9671c064dad78d</td>\n",
       "      <td>20b868b8909142c2a2b6755e48a6e90f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   bank                               rtk\n",
       "8253   6783adb24efc43549038a0c037c958e7  036395725c6a4454bbabdcbca9e299f2\n",
       "171    ed1ab56022944a8b8c5799929ef85e32  543f9e92c965432e9fe04220bfa46e3b\n",
       "8256   43cfd421f06343a5ae5ab1c07b442031  da8ecc0632664c9f8e7935a7d4fbdebd\n",
       "4207   0f9b40ccb74a43aba8017ae10f0c54e1  113d266f48df4eb5a6d455cf153661ef\n",
       "10151  1a5a3b9697bb45d78f9671c064dad78d  20b868b8909142c2a2b6755e48a6e90f"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_matching = pd.read_csv('train_matching.csv')\n",
    "print(f'Data shape: {train_matching.shape}')\n",
    "train_matching.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6c23a8",
   "metadata": {},
   "source": [
    "To solve this task let's choose only such pairs between which bijective mapping is exist.  \n",
    "Limit of chossing is 5000 pairs because of memory lack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbfa2482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of unique clients: \n",
      "[bank]: 5000 \n",
      "[clickstream]: 5000\n",
      "Wall time: 31 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "train_matching = train_matching[~train_matching['rtk'].isin(['0'])].sample(5000).reset_index(drop=True)\n",
    "\n",
    "users_bank = train_matching['bank'].unique().tolist()\n",
    "users_rtk = train_matching['rtk'].unique().tolist()\n",
    "\n",
    "print(f'Amount of unique clients: \\n[bank]: {len(users_bank)} \\n[clickstream]: {len(users_rtk)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4580479b",
   "metadata": {},
   "source": [
    "Let's load transactions data and make train dataset at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86fc5bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:32<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4432260, 5)\n",
      "Memory usage: 202 Mb\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.join(MAIN_PATH, 'parquets'))\n",
    "\n",
    "\n",
    "def select_bank_users_train(data): return data[data['user_id'].isin(users_bank)]\n",
    "\n",
    "\n",
    "train_transactions = Parallel(n_jobs=-1)(delayed(select_bank_users_train)(\n",
    "    pd.read_parquet(f'bank{i}.parquet', engine='fastparquet')) for i in trange(20))\n",
    "\n",
    "df_bank_train = pd.concat(train_transactions)\n",
    "print(df_bank_train.shape)\n",
    "print(f\"Memory usage: {df_bank_train.memory_usage().sum() // 1024 ** 2} Mb\")\n",
    "\n",
    "del train_transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfaaea5",
   "metadata": {},
   "source": [
    "Let's take a look at columns of this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c2c4e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['user_id', 'mcc_code', 'currency_rk', 'transaction_amt', 'transaction_dttm']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "list(df_bank_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3db38e",
   "metadata": {},
   "source": [
    "Let's look at 5 random samples from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2214658b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.18 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>mcc_code</th>\n",
       "      <th>currency_rk</th>\n",
       "      <th>transaction_amt</th>\n",
       "      <th>transaction_dttm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18477270</th>\n",
       "      <td>eec6fe9b4fef41b998d4cc06be99b69f</td>\n",
       "      <td>4131</td>\n",
       "      <td>48</td>\n",
       "      <td>-27.049622</td>\n",
       "      <td>2020-09-22 01:48:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14609473</th>\n",
       "      <td>bbe082c9701e45a9a391e940bceee703</td>\n",
       "      <td>5499</td>\n",
       "      <td>48</td>\n",
       "      <td>-1373.477900</td>\n",
       "      <td>2021-05-04 03:43:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19277167</th>\n",
       "      <td>f995027a786a40cbb5bdae56f6677bcd</td>\n",
       "      <td>4829</td>\n",
       "      <td>48</td>\n",
       "      <td>558.444640</td>\n",
       "      <td>2020-12-13 15:52:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12408073</th>\n",
       "      <td>9faf5b2c0b5c4cbd925a8d6311f8a63b</td>\n",
       "      <td>5541</td>\n",
       "      <td>48</td>\n",
       "      <td>-110.562584</td>\n",
       "      <td>2021-06-03 00:27:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7575802</th>\n",
       "      <td>60f2860b80094c7fa11eabb5b1798b9d</td>\n",
       "      <td>5411</td>\n",
       "      <td>48</td>\n",
       "      <td>-3114.122600</td>\n",
       "      <td>2021-03-05 05:43:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   user_id  mcc_code  currency_rk  \\\n",
       "18477270  eec6fe9b4fef41b998d4cc06be99b69f      4131           48   \n",
       "14609473  bbe082c9701e45a9a391e940bceee703      5499           48   \n",
       "19277167  f995027a786a40cbb5bdae56f6677bcd      4829           48   \n",
       "12408073  9faf5b2c0b5c4cbd925a8d6311f8a63b      5541           48   \n",
       "7575802   60f2860b80094c7fa11eabb5b1798b9d      5411           48   \n",
       "\n",
       "          transaction_amt     transaction_dttm  \n",
       "18477270       -27.049622  2020-09-22 01:48:38  \n",
       "14609473     -1373.477900  2021-05-04 03:43:46  \n",
       "19277167       558.444640  2020-12-13 15:52:23  \n",
       "12408073      -110.562584  2021-06-03 00:27:39  \n",
       "7575802      -3114.122600  2021-03-05 05:43:07  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_bank_train.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58626ac5",
   "metadata": {},
   "source": [
    "Let's check unique values for 'mcc_code' and 'currency_rk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "026dd228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values: \n",
      "[mcc_code]: 338\n",
      "Great amount for pretty printing\n",
      "[currency_rk]: 4\n",
      "[48 -1 50 60]\n",
      "Wall time: 432 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(f\"Unique values: \\n[mcc_code]: {df_bank_train['mcc_code'].nunique()}\")\n",
    "if df_bank_train['mcc_code'].nunique() < 10:\n",
    "    print(df_bank_train['mcc_code'].unique())\n",
    "else:\n",
    "    print(\"Great amount for pretty printing\")\n",
    "    \n",
    "print(f\"[currency_rk]: {df_bank_train['currency_rk'].nunique()}\")\n",
    "if df_bank_train['currency_rk'].nunique() < 10:\n",
    "    print(df_bank_train['currency_rk'].unique())\n",
    "else:\n",
    "    print(\"Great amount for pretty printing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556965cb",
   "metadata": {},
   "source": [
    "This data includes 5000 unique clients that we have chosen early.  \n",
    "This feature \"transaction_dttm\" can be converted to datetime format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caa5be5",
   "metadata": {},
   "source": [
    "Now let's load clickstreaming service data and make train dataset at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb6f6b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 127/127 [02:48<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30762259, 4)\n",
      "Memory usage: 1173 Mb\n"
     ]
    }
   ],
   "source": [
    "def select_rtk_users_train(data): return data[data['user_id'].isin(users_rtk)]\n",
    "\n",
    "\n",
    "clicksreaming_train = Parallel(n_jobs=-1)(delayed(select_rtk_users_train)(\n",
    "    pd.read_parquet(f'click{i}.parquet', engine='fastparquet')) for i in trange(127))\n",
    "\n",
    "df_rtk_train = pd.concat(clicksreaming_train)\n",
    "print(df_rtk_train.shape)\n",
    "print(f\"Memory usage: {df_rtk_train.memory_usage().sum() // 1024 ** 2} Mb\")\n",
    "\n",
    "del clicksreaming_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c008e12",
   "metadata": {},
   "source": [
    "Let's take a look at columns of this data and 5 random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73ac9443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_id', 'cat_id', 'timestamp', 'new_uid']\n",
      "Wall time: 8.55 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>new_uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37738683</th>\n",
       "      <td>519ec98d6b284cf880fac1d862b0b6bc</td>\n",
       "      <td>289</td>\n",
       "      <td>2021-02-25 14:08:00</td>\n",
       "      <td>1384344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57839838</th>\n",
       "      <td>758df89106bc4f5780fbe13543986a37</td>\n",
       "      <td>165</td>\n",
       "      <td>2021-05-06 05:25:00</td>\n",
       "      <td>754072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15043655</th>\n",
       "      <td>220f5acda0274829a5d9a96e6fd08ae5</td>\n",
       "      <td>251</td>\n",
       "      <td>2021-05-18 14:14:00</td>\n",
       "      <td>591797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46393041</th>\n",
       "      <td>628709ff22e142d1a1bd2993dcb00ea6</td>\n",
       "      <td>535</td>\n",
       "      <td>2021-03-21 16:12:00</td>\n",
       "      <td>1061068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96486108</th>\n",
       "      <td>c485a7de877d44daaafe5ff804f6b665</td>\n",
       "      <td>931</td>\n",
       "      <td>2021-02-16 13:56:00</td>\n",
       "      <td>554594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   user_id  cat_id            timestamp  \\\n",
       "37738683  519ec98d6b284cf880fac1d862b0b6bc     289  2021-02-25 14:08:00   \n",
       "57839838  758df89106bc4f5780fbe13543986a37     165  2021-05-06 05:25:00   \n",
       "15043655  220f5acda0274829a5d9a96e6fd08ae5     251  2021-05-18 14:14:00   \n",
       "46393041  628709ff22e142d1a1bd2993dcb00ea6     535  2021-03-21 16:12:00   \n",
       "96486108  c485a7de877d44daaafe5ff804f6b665     931  2021-02-16 13:56:00   \n",
       "\n",
       "          new_uid  \n",
       "37738683  1384344  \n",
       "57839838   754072  \n",
       "15043655   591797  \n",
       "46393041  1061068  \n",
       "96486108   554594  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(list(df_rtk_train))\n",
    "df_rtk_train.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62411dc",
   "metadata": {},
   "source": [
    "This data also includes 5000 unique clients and contains of one feature (\"timestamp\") that can be converted to datetime format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bc3ad7",
   "metadata": {},
   "source": [
    "Let's check unique values for 'cat_id' and 'new_uid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c210eacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values: \n",
      "[cat_id]: 321\n",
      "Great amount for pretty printing\n",
      "[new_uid]: 20014\n",
      "Great amount for pretty printing\n",
      "Wall time: 1.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(f\"Unique values: \\n[cat_id]: {df_rtk_train['cat_id'].nunique()}\")\n",
    "if df_rtk_train['cat_id'].nunique() < 10:\n",
    "    print(df_rtk_train['cat_id'].unique())\n",
    "else:\n",
    "    print(\"Great amount for pretty printing\")\n",
    "    \n",
    "print(f\"[new_uid]: {df_rtk_train['new_uid'].nunique()}\")\n",
    "if df_rtk_train['new_uid'].nunique() < 10:\n",
    "    print(df_rtk_train['new_uid'].unique())\n",
    "else:\n",
    "    print(\"Great amount for pretty printing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24453d9",
   "metadata": {},
   "source": [
    "## 2 Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b9c973",
   "metadata": {},
   "source": [
    "Using initialised functions for generating features let's define working features space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2cd83e",
   "metadata": {},
   "source": [
    "Arguments for generating features function that contain information about making activities by hours:\n",
    "\n",
    "- for transactions:\n",
    "\n",
    "    - time_col: transaction_dttm;\n",
    "    - value_col: transaction_amt;\n",
    "    - prefix: bank;\n",
    "    \n",
    "- for clickstreaming service:\n",
    "\n",
    "    - time_col: timestamp;\n",
    "    - value_col: timestamp;\n",
    "    - prefix: click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6632ee37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (5000, 1840)\n",
      "Memory usage: 35 Mb\n",
      "--------------------\n",
      "Shape: (5000, 346)\n",
      "Memory usage: 6 Mb\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bank_hours_train = make_hours_features(df_bank_train, time_col='transaction_dttm',\n",
    "                                       value_col='transaction_amt', prefix='bank')\n",
    "bank_embed_train = make_base_bank_features(df_bank_train)\n",
    "bank_embed_train = bank_embed_train.join(bank_hours_train)\n",
    "\n",
    "print(f\"Shape: {bank_embed_train.shape}\")\n",
    "print(f\"Memory usage: {bank_embed_train.memory_usage().sum() // 1024 ** 2} Mb\")\n",
    "\n",
    "print(20*'-')\n",
    "\n",
    "rtk_hours_train = make_hours_features(df_rtk_train, time_col='timestamp', value_col='timestamp', prefix='click')\n",
    "rtk_embed_train = make_base_rtk_features(df_rtk_train)\n",
    "rtk_embed_train = rtk_embed_train.join(rtk_hours_train)\n",
    "\n",
    "print(f\"Shape: {rtk_embed_train.shape}\")\n",
    "print(f\"Memory usage: {rtk_embed_train.memory_usage().sum() // 1024 ** 2} Mb\")\n",
    "\n",
    "del df_bank_train, df_rtk_train\n",
    "del bank_hours_train, rtk_hours_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c9bab1",
   "metadata": {},
   "source": [
    "After feature engineering there are 1840 features for transactions data and 346 features for clickstreaming service data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcec4dfc",
   "metadata": {},
   "source": [
    "Let's check \"nan\" value in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e550c800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[transactions]: 0 \n",
      "[clickstream] 0\n",
      "Wall time: 588 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(f\"[transactions]: {(bank_embed_train.isna().sum()).sum()} \\n[clickstream] {(rtk_embed_train.isna().sum()).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875d6577",
   "metadata": {},
   "source": [
    "Let's check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b84686cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[transactions]: 0 \n",
      "[clickstream] 0\n",
      "Wall time: 1.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(f\"[transactions]: {bank_embed_train.duplicated().sum()} \\n[clickstream] {rtk_embed_train.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9197c070",
   "metadata": {},
   "source": [
    "So, there aren't \"nan\" values and duplicates in data.  \n",
    "Now let's split the data into train and validation parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d4c7b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: \n",
      "[transactions]: (1000, 1840) \n",
      "[clickstream]: (1000, 346)\n",
      "----------------------------------------\n",
      "Shape: \n",
      "[transactions]: (4000, 1840) \n",
      "[clickstream]: (4000, 346)\n",
      "Wall time: 305 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "val_indexes = np.random.choice(users_bank, 1000, replace=False)\n",
    "valid_matching = train_matching[train_matching['bank'].isin(val_indexes)]\n",
    "\n",
    "bank_embed_valid = bank_embed_train.loc[valid_matching['bank'].unique()]\n",
    "rtk_embed_valid = rtk_embed_train.loc[valid_matching['rtk'].unique()]\n",
    "print(f'Shape: \\n[transactions]: {bank_embed_valid.shape} \\n[clickstream]: {rtk_embed_valid.shape}')\n",
    "\n",
    "print(40*'-')\n",
    "\n",
    "train_matching = train_matching[~train_matching['bank'].isin(val_indexes)]\n",
    "\n",
    "bank_embed_train = bank_embed_train.loc[train_matching['bank'].unique()]\n",
    "rtk_embed_train = rtk_embed_train.loc[train_matching['rtk'].unique()]\n",
    "print(f'Shape: \\n[transactions]: {bank_embed_train.shape} \\n[clickstream]: {rtk_embed_train.shape}')\n",
    "\n",
    "del val_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8221353",
   "metadata": {},
   "source": [
    "## 3 Train data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed629f4",
   "metadata": {},
   "source": [
    "Let's set truly labels for matching and generate 10 negative samples.  \n",
    "For this goal I'll use function \"gen_random_for_negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dec76cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 964 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "train_mathing_rtk_unique = train_matching['rtk'].unique()\n",
    "train_matching['negatives'] = train_matching['rtk'].apply(\n",
    "    lambda x: gen_random_for_negative(x, 10, train_mathing_rtk_unique)\n",
    ")\n",
    "\n",
    "train_matching['target'] = 1\n",
    "\n",
    "positive_train = train_matching[['bank', 'rtk', 'target']]\n",
    "negative_train = train_matching[['bank', 'negatives']].explode('negatives')\n",
    "\n",
    "negative_train['target'] = 0\n",
    "negative_train.columns = positive_train.columns\n",
    "\n",
    "full_train = pd.concat([positive_train, negative_train]).sort_values(by='bank')\n",
    "\n",
    "del train_matching, train_mathing_rtk_unique\n",
    "del positive_train, negative_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830646e6",
   "metadata": {},
   "source": [
    "Let's take a look at 5 random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e540f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>rtk</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3677</th>\n",
       "      <td>fc042614b80046ff8b1724f8ab48747c</td>\n",
       "      <td>5ae64af1013f48fab63028f75c5db1ae</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4414</th>\n",
       "      <td>366bd7c4be8d4a6494451c76212ad6ef</td>\n",
       "      <td>66df362224d946a68f59302dcd244718</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>4631e0fdc8714601a63ffdea84627ce5</td>\n",
       "      <td>2a0dadb3b0b1409f889eb3a4af57cf3e</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3992</th>\n",
       "      <td>f36152eefb1549ac83482b432cd606c0</td>\n",
       "      <td>feba37f3c01045a7a7ffcec2af9483d5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>a86e8e61e76f4390a072e191395963ba</td>\n",
       "      <td>a25d6d83564044fea7e3d1b022fe4b62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  bank                               rtk  \\\n",
       "3677  fc042614b80046ff8b1724f8ab48747c  5ae64af1013f48fab63028f75c5db1ae   \n",
       "4414  366bd7c4be8d4a6494451c76212ad6ef  66df362224d946a68f59302dcd244718   \n",
       "593   4631e0fdc8714601a63ffdea84627ce5  2a0dadb3b0b1409f889eb3a4af57cf3e   \n",
       "3992  f36152eefb1549ac83482b432cd606c0  feba37f3c01045a7a7ffcec2af9483d5   \n",
       "1863  a86e8e61e76f4390a072e191395963ba  a25d6d83564044fea7e3d1b022fe4b62   \n",
       "\n",
       "      target  \n",
       "3677       0  \n",
       "4414       0  \n",
       "593        0  \n",
       "3992       0  \n",
       "1863       0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "full_train.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6901db47",
   "metadata": {},
   "source": [
    "It's necessary to convert target variable to \"int8\" type aiming to reduce memory usage.  \n",
    "Current type of target in int64. It's overkill for binary variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcb0fe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train['target'] = full_train['target'].astype('int8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb7b1e9",
   "metadata": {},
   "source": [
    "Finally to obtain full train dataset it's necessary to merge all separate parts into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3112df1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (44000, 2189)\n",
      "Memory usage: 367 Mb\n",
      "Wall time: 2.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "full_train = full_train.merge(bank_embed_train, how='left', left_on='bank', right_index=True)\\\n",
    "                       .merge(rtk_embed_train, how='left', left_on='rtk', right_index=True).fillna(0)\n",
    "\n",
    "print(f\"Shape: {full_train.shape}\")\n",
    "print(f\"Memory usage: {full_train.memory_usage().sum() // 1024 ** 2} Mb\")\n",
    "\n",
    "del bank_embed_train, rtk_embed_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd52f99",
   "metadata": {},
   "source": [
    "Let's take a look at 5 random sample from full train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b71bf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>rtk</th>\n",
       "      <th>target</th>\n",
       "      <th>sum--1</th>\n",
       "      <th>sum-48</th>\n",
       "      <th>sum-50</th>\n",
       "      <th>sum-60</th>\n",
       "      <th>mean--1</th>\n",
       "      <th>mean-48</th>\n",
       "      <th>mean-50</th>\n",
       "      <th>...</th>\n",
       "      <th>click_15h</th>\n",
       "      <th>click_16h</th>\n",
       "      <th>click_17h</th>\n",
       "      <th>click_18h</th>\n",
       "      <th>click_19h</th>\n",
       "      <th>click_20h</th>\n",
       "      <th>click_21h</th>\n",
       "      <th>click_22h</th>\n",
       "      <th>click_23h</th>\n",
       "      <th>click_sumh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4702</th>\n",
       "      <td>96cefcd25e9e42cbb665cd4be60cad5e</td>\n",
       "      <td>00c611f241cd4ae4992477f99c3be590</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.775215e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-191.295792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052027</td>\n",
       "      <td>0.050676</td>\n",
       "      <td>0.059459</td>\n",
       "      <td>0.098649</td>\n",
       "      <td>0.062162</td>\n",
       "      <td>0.029730</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>0.003378</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3915</th>\n",
       "      <td>4babb230498741d991756ffbca9f9e2e</td>\n",
       "      <td>4b02b923770f4b078b695ab931a15673</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441110</td>\n",
       "      <td>-3.365493e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.441110</td>\n",
       "      <td>-492.031097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058651</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.152493</td>\n",
       "      <td>0.155425</td>\n",
       "      <td>0.085044</td>\n",
       "      <td>0.023460</td>\n",
       "      <td>0.017595</td>\n",
       "      <td>0.014663</td>\n",
       "      <td>0.020528</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956</th>\n",
       "      <td>03ca4ea2cf474fa185f9ce23bae2debe</td>\n",
       "      <td>4dab2d99cbc149bbb11c3c9c576a2d7f</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.081661e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-535.475342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089219</td>\n",
       "      <td>0.089219</td>\n",
       "      <td>0.089219</td>\n",
       "      <td>0.081784</td>\n",
       "      <td>0.066914</td>\n",
       "      <td>0.022305</td>\n",
       "      <td>0.011152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>da3b5a2a2aa44847b5cb8bfb74577d1e</td>\n",
       "      <td>552e3ffecaab4ceebfa8a3bd7a6e9ad6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.060248</td>\n",
       "      <td>-1.250813e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>-953.363403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071540</td>\n",
       "      <td>0.059556</td>\n",
       "      <td>0.047317</td>\n",
       "      <td>0.032383</td>\n",
       "      <td>0.017484</td>\n",
       "      <td>0.011729</td>\n",
       "      <td>0.008050</td>\n",
       "      <td>0.008050</td>\n",
       "      <td>0.010418</td>\n",
       "      <td>27453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304</th>\n",
       "      <td>22e6f99cc51f476baa06ce29c0acc386</td>\n",
       "      <td>42efd3a305414928b4f87a547ff62f28</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.555836e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-537.947998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.007545</td>\n",
       "      <td>0.006859</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2189 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  bank                               rtk  \\\n",
       "4702  96cefcd25e9e42cbb665cd4be60cad5e  00c611f241cd4ae4992477f99c3be590   \n",
       "3915  4babb230498741d991756ffbca9f9e2e  4b02b923770f4b078b695ab931a15673   \n",
       "1956  03ca4ea2cf474fa185f9ce23bae2debe  4dab2d99cbc149bbb11c3c9c576a2d7f   \n",
       "1102  da3b5a2a2aa44847b5cb8bfb74577d1e  552e3ffecaab4ceebfa8a3bd7a6e9ad6   \n",
       "2304  22e6f99cc51f476baa06ce29c0acc386  42efd3a305414928b4f87a547ff62f28   \n",
       "\n",
       "      target    sum--1        sum-48  sum-50  sum-60   mean--1     mean-48  \\\n",
       "4702       0  0.000000 -9.775215e+04     0.0     0.0  0.000000 -191.295792   \n",
       "3915       0  0.441110 -3.365493e+05     0.0     0.0  0.441110 -492.031097   \n",
       "1956       0  0.000000 -5.081661e+05     0.0     0.0  0.000000 -535.475342   \n",
       "1102       0  0.060248 -1.250813e+06     0.0     0.0  0.001545 -953.363403   \n",
       "2304       0  0.000000 -3.555836e+05     0.0     0.0  0.000000 -537.947998   \n",
       "\n",
       "      mean-50  ...  click_15h  click_16h  click_17h  click_18h  click_19h  \\\n",
       "4702      0.0  ...   0.052027   0.050676   0.059459   0.098649   0.062162   \n",
       "3915      0.0  ...   0.058651   0.129032   0.152493   0.155425   0.085044   \n",
       "1956      0.0  ...   0.089219   0.089219   0.089219   0.081784   0.066914   \n",
       "1102      0.0  ...   0.071540   0.059556   0.047317   0.032383   0.017484   \n",
       "2304      0.0  ...   0.009259   0.007545   0.006859   0.001372   0.000343   \n",
       "\n",
       "      click_20h  click_21h  click_22h  click_23h  click_sumh  \n",
       "4702   0.029730   0.002027   0.003378   0.004054        1480  \n",
       "3915   0.023460   0.017595   0.014663   0.020528         341  \n",
       "1956   0.022305   0.011152   0.000000   0.000000         269  \n",
       "1102   0.011729   0.008050   0.008050   0.010418       27453  \n",
       "2304   0.000000   0.000000   0.000000   0.000000        2916  \n",
       "\n",
       "[5 rows x 2189 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "full_train.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc41734",
   "metadata": {},
   "source": [
    "## 4 Model fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f2dfd0",
   "metadata": {},
   "source": [
    "Here I considered it's better to use cross validation strategy for estimating model precision but it'll take more than 2 days to fit model. That's why I just take hold out part form the data to evaluate model during fiiting.\n",
    "\n",
    "Size of hold out part is 10% from full train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4bdbe66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[hold_out]: (4400, 2189) \n",
      "[train]: (39600, 2189)\n",
      "Wall time: 686 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hold_out_size = int(0.1*len(full_train['bank'].unique()))\n",
    "hold_out = full_train[full_train['bank'].isin(full_train['bank'].unique()[:hold_out_size])]\n",
    "train = full_train[full_train['bank'].isin(full_train['bank'].unique()[hold_out_size:])]\n",
    "print(f\"[hold_out]: {hold_out.shape} \\n[train]: {train.shape}\")\n",
    "\n",
    "del hold_out_size, full_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c3d760",
   "metadata": {},
   "source": [
    "Let's set full features because it'll be used in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "185c8518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features total amount: 2186\n",
      "Wall time: 14 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "features = train.columns[3:].to_list()\n",
    "print(f\"Features total amount: {len(features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e8363e",
   "metadata": {},
   "source": [
    "I use CatBoostClassifier as the main model.\n",
    "\n",
    "Some settings:\n",
    "\n",
    "- iterations: 2000;\n",
    "- depth: 12;\n",
    "- learning_rate: 0.01;\n",
    "- loss_function: CrossEntropy;\n",
    "- eval_set: (hold_out[features], hold_out['target']);\n",
    "- verbose: 50;\n",
    "- early_stopping_rounds: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db816b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6837565\ttest: 0.6838021\tbest: 0.6838021 (0)\ttotal: 20.7s\tremaining: 11h 28m 21s\n",
      "50:\tlearn: 0.4180662\ttest: 0.4188100\tbest: 0.4188100 (50)\ttotal: 16m 5s\tremaining: 10h 14m 43s\n",
      "100:\tlearn: 0.3392136\ttest: 0.3402524\tbest: 0.3402524 (100)\ttotal: 31m 43s\tremaining: 9h 56m 22s\n",
      "150:\tlearn: 0.3118588\ttest: 0.3138610\tbest: 0.3138610 (150)\ttotal: 47m 4s\tremaining: 9h 36m 22s\n",
      "200:\tlearn: 0.2995091\ttest: 0.3031644\tbest: 0.3031644 (200)\ttotal: 1h 2m 58s\tremaining: 9h 23m 42s\n",
      "250:\tlearn: 0.2899102\ttest: 0.2974085\tbest: 0.2974085 (250)\ttotal: 1h 18m 21s\tremaining: 9h 6m\n",
      "300:\tlearn: 0.2817377\ttest: 0.2936669\tbest: 0.2936669 (300)\ttotal: 1h 35m 8s\tremaining: 8h 57m 3s\n",
      "350:\tlearn: 0.2711053\ttest: 0.2902317\tbest: 0.2902317 (350)\ttotal: 1h 51m 43s\tremaining: 8h 44m 52s\n",
      "400:\tlearn: 0.2627374\ttest: 0.2881249\tbest: 0.2881249 (400)\ttotal: 2h 8m 35s\tremaining: 8h 32m 44s\n",
      "450:\tlearn: 0.2552396\ttest: 0.2866283\tbest: 0.2866283 (450)\ttotal: 2h 25m 22s\tremaining: 8h 19m 16s\n",
      "500:\tlearn: 0.2476738\ttest: 0.2851704\tbest: 0.2851702 (499)\ttotal: 2h 42m 15s\tremaining: 8h 5m 29s\n",
      "550:\tlearn: 0.2395686\ttest: 0.2839417\tbest: 0.2839417 (550)\ttotal: 2h 59m 7s\tremaining: 7h 51m 3s\n",
      "600:\tlearn: 0.2327773\ttest: 0.2831058\tbest: 0.2831058 (600)\ttotal: 3h 15m 37s\tremaining: 7h 35m 23s\n",
      "650:\tlearn: 0.2271428\ttest: 0.2824767\tbest: 0.2824277 (641)\ttotal: 3h 32m 24s\tremaining: 7h 20m 8s\n",
      "700:\tlearn: 0.2221200\ttest: 0.2819630\tbest: 0.2819593 (698)\ttotal: 3h 49m 12s\tremaining: 7h 4m 43s\n",
      "750:\tlearn: 0.2162508\ttest: 0.2813823\tbest: 0.2813125 (745)\ttotal: 4h 6m 4s\tremaining: 6h 49m 14s\n",
      "800:\tlearn: 0.2109362\ttest: 0.2806390\tbest: 0.2806390 (800)\ttotal: 4h 22m 53s\tremaining: 6h 33m 30s\n",
      "850:\tlearn: 0.2060435\ttest: 0.2802044\tbest: 0.2801843 (849)\ttotal: 4h 39m 48s\tremaining: 6h 17m 47s\n",
      "900:\tlearn: 0.2015339\ttest: 0.2797310\tbest: 0.2797154 (899)\ttotal: 4h 56m 24s\tremaining: 6h 1m 32s\n",
      "950:\tlearn: 0.1967566\ttest: 0.2792032\tbest: 0.2792032 (950)\ttotal: 5h 13m 18s\tremaining: 5h 45m 35s\n",
      "1000:\tlearn: 0.1906539\ttest: 0.2788088\tbest: 0.2788055 (995)\ttotal: 5h 30m 10s\tremaining: 5h 29m 30s\n",
      "1050:\tlearn: 0.1862519\ttest: 0.2783810\tbest: 0.2783810 (1050)\ttotal: 5h 46m 39s\tremaining: 5h 13m\n",
      "1100:\tlearn: 0.1808432\ttest: 0.2780488\tbest: 0.2780488 (1100)\ttotal: 6h 3m 32s\tremaining: 4h 56m 50s\n",
      "1150:\tlearn: 0.1763383\ttest: 0.2777836\tbest: 0.2777836 (1150)\ttotal: 6h 20m 37s\tremaining: 4h 40m 45s\n",
      "1200:\tlearn: 0.1721900\ttest: 0.2775960\tbest: 0.2775960 (1200)\ttotal: 6h 38m 31s\tremaining: 4h 25m 7s\n",
      "1250:\tlearn: 0.1666941\ttest: 0.2772910\tbest: 0.2772749 (1245)\ttotal: 6h 55m 22s\tremaining: 4h 8m 41s\n",
      "1300:\tlearn: 0.1611378\ttest: 0.2769955\tbest: 0.2769955 (1300)\ttotal: 7h 12m 13s\tremaining: 3h 52m 13s\n",
      "1350:\tlearn: 0.1552537\ttest: 0.2768860\tbest: 0.2768470 (1333)\ttotal: 7h 29m 6s\tremaining: 3h 35m 44s\n",
      "1400:\tlearn: 0.1503441\ttest: 0.2768448\tbest: 0.2767709 (1374)\ttotal: 7h 46m\tremaining: 3h 19m 14s\n",
      "1450:\tlearn: 0.1458559\ttest: 0.2768290\tbest: 0.2767709 (1374)\ttotal: 8h 2m 55s\tremaining: 3h 2m 43s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.2767709356\n",
      "bestIteration = 1374\n",
      "\n",
      "Shrink model to first 1375 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x231db531bb0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    iterations=2000,\n",
    "    depth=12,\n",
    "    learning_rate=0.01,\n",
    "    loss_function='CrossEntropy'\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train[features],\n",
    "    train['target'],\n",
    "    eval_set=(hold_out[features], hold_out['target']),\n",
    "    verbose=50,\n",
    "    early_stopping_rounds=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6344da1e",
   "metadata": {},
   "source": [
    "I don't need anymore train datasets and all information that belongs to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27b3f891",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train, hold_out\n",
    "del users_bank, users_rtk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f3e1b1",
   "metadata": {},
   "source": [
    "## 5 Model validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d09c80",
   "metadata": {},
   "source": [
    "Let's create the base structure for validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c69f0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 49.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "validation_results = pd.DataFrame(columns=['bank'], data=bank_embed_valid.index.to_list())\n",
    "validation_results['rtk'] = validation_results['bank'].apply(lambda x: rtk_embed_valid.index.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd51de3d",
   "metadata": {},
   "source": [
    "Predicting matching for validation data will be produced for 200 elements at once.  \n",
    "Taking it into account it's necessary 5 batches to predict matching for all validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9c4841b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 200\n",
    "num_of_batches = int((len(bank_embed_valid.index.to_list()))/batch_size)\n",
    "num_of_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b81183",
   "metadata": {},
   "source": [
    "So, let's predict matching for validation pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "167eb2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [01:12<00:00, 14.50s/it]\n"
     ]
    }
   ],
   "source": [
    "validation_done = []\n",
    "for batch in trange(num_of_batches):\n",
    "    \n",
    "    bank_indexes = bank_embed_valid.index.to_list()[(batch*batch_size):((batch+1)*batch_size)]\n",
    "    \n",
    "    if len(bank_indexes) != 0:\n",
    "        \n",
    "        part_of_validation = validation_results[validation_results['bank'].isin(bank_indexes)].explode('rtk')\n",
    "        part_of_validation = part_of_validation.merge(bank_embed_valid, how='left', left_on='bank', right_index=True)\\\n",
    "                                               .merge(rtk_embed_valid, how='left', left_on='rtk', right_index=True)\\\n",
    "                                               .fillna(0)\n",
    "\n",
    "        part_of_validation['predicts'] = model.predict_proba(part_of_validation[features])[:,1]\n",
    "        part_of_validation = part_of_validation[['bank', 'rtk', 'predicts']]        \n",
    "        part_of_validation = part_of_validation.sort_values(by=['bank', 'predicts'], ascending=False)\\\n",
    "                             .reset_index(drop=True)\n",
    "        part_of_validation = part_of_validation.pivot_table(index='bank', values='rtk', aggfunc=list)\n",
    "        part_of_validation['rtk'] = part_of_validation['rtk'].apply(lambda x: x[:100])\n",
    "        part_of_validation['bank'] = part_of_validation.index\n",
    "        part_of_validation = part_of_validation[['bank', 'rtk']]\n",
    "        \n",
    "        validation_done.append(part_of_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cf74d4",
   "metadata": {},
   "source": [
    "Finally, it's necessary to bring to the desired structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf1d087b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1000, 3)\n",
      "Wall time: 1.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "validation_final = pd.concat(validation_done)\n",
    "validation_final.reset_index(inplace=True, drop=True)\n",
    "validation_final['true_rtk'] = validation_final['bank'].apply(\n",
    "    lambda x: valid_matching[valid_matching['bank'].isin([x])]['rtk'].values[0])\n",
    "print(f\"Shape: {validation_final.shape}\")\n",
    "\n",
    "del bank_embed_valid, rtk_embed_valid, bank_indexes\n",
    "del validation_results, part_of_validation, validation_done\n",
    "del batch_size, num_of_batches, batch\n",
    "del valid_matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fea5ff0",
   "metadata": {},
   "source": [
    "R1 metric calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03b103f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.367 \n",
      "MRR: 0.0405715495 \n",
      "R1: 0.0730657412\n",
      "Wall time: 69.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "precision, mrr = 0, 0\n",
    "for idx in range(len(validation_final)):\n",
    "    \n",
    "    true = validation_final['true_rtk'].loc[idx]\n",
    "    preds = validation_final['rtk'].loc[idx]\n",
    "\n",
    "    if true in preds:\n",
    "        precision += 1\n",
    "        mrr += 1 / (preds.index(true) + 1)\n",
    "precision = precision / len(validation_final)\n",
    "mrr = mrr / len(validation_final)\n",
    "r1 = (2 * precision * mrr) / (precision + mrr)\n",
    "print(f'Precision: {round(precision, ndigits=10)} \\nMRR: {round(mrr, ndigits=10)} \\nR1: {round(r1, ndigits=10)}')\n",
    "\n",
    "del validation_final\n",
    "del idx, precision, mrr\n",
    "del true, preds, r1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86c8690",
   "metadata": {},
   "source": [
    "I've got some optimistic results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dd3024",
   "metadata": {},
   "source": [
    "Main influence in this metric plays MRR@k. If you'll have high Precision@k, but MRR@k is too low you'll get low R1 too.  \n",
    "So it's necessary to see right proportional changing between MRR@k and R1 only in direction but not in values changing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ddaad6",
   "metadata": {},
   "source": [
    "## 6 Test data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed35c12",
   "metadata": {},
   "source": [
    "Let's load data that contain information about candidates to pairs for bank clients. This is the main file for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "64ac09e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (4952, 2)\n",
      "Amount of unique clients: \n",
      "[bank]: 4952 \n",
      "[clickstream]: 4952\n",
      "Wall time: 62.5 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>rtk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>45284b9689f94a6b9519837ff81efaf6</td>\n",
       "      <td>445f444647ed42bcada41a1e82d31abe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>6b9c28fda1534d958098af89f9126dee</td>\n",
       "      <td>944ffb6af1834d6da3f11ffebeb9c97b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1957</th>\n",
       "      <td>91f9fe21c534470f91a68c9b0e28129c</td>\n",
       "      <td>4dbfbc35971d467383b845b3aaa3b8ed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3464</th>\n",
       "      <td>eaf003b643aa498bb23346c14248fc7c</td>\n",
       "      <td>b164633f115c46e9a54a4c5676f048ea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4473</th>\n",
       "      <td>bbf0757110f345a9baeb88374e580297</td>\n",
       "      <td>cfc1b16c6c0f4da6a7cdc0ff0c5b26fa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  bank                               rtk\n",
       "230   45284b9689f94a6b9519837ff81efaf6  445f444647ed42bcada41a1e82d31abe\n",
       "1371  6b9c28fda1534d958098af89f9126dee  944ffb6af1834d6da3f11ffebeb9c97b\n",
       "1957  91f9fe21c534470f91a68c9b0e28129c  4dbfbc35971d467383b845b3aaa3b8ed\n",
       "3464  eaf003b643aa498bb23346c14248fc7c  b164633f115c46e9a54a4c5676f048ea\n",
       "4473  bbf0757110f345a9baeb88374e580297  cfc1b16c6c0f4da6a7cdc0ff0c5b26fa"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "os.chdir(MAIN_PATH)\n",
    "\n",
    "test = pd.read_csv('puzzle.csv')\n",
    "print(f'Shape: {test.shape}')\n",
    "\n",
    "test_bank_users = test['bank'].unique()\n",
    "test_rtk_users = test['rtk'].unique()\n",
    "print(f'Amount of unique clients: \\n[bank]: {len(test_bank_users)} \\n[clickstream]: {len(test_rtk_users)}')\n",
    "\n",
    "test.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a9dae3",
   "metadata": {},
   "source": [
    "Test mapping data doesn't contain zero mapping, i.e. every bank client has definitely clickstreaming service client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a97f530",
   "metadata": {},
   "source": [
    "Let's load transactions data and make test dataset at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "789d9798",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:28<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4381342, 5)\n",
      "Memory usage: 200 Mb\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.join(MAIN_PATH, 'parquets'))\n",
    "\n",
    "\n",
    "def select_bank_users_test(data): return data[data['user_id'].isin(test_bank_users)]\n",
    "\n",
    "\n",
    "test_transactions = Parallel(n_jobs=-1)(delayed(select_bank_users_test)(\n",
    "    pd.read_parquet(f'bank{i}.parquet', engine='fastparquet')) for i in trange(20))\n",
    "\n",
    "test_bank = pd.concat(test_transactions)\n",
    "print(test_bank.shape)\n",
    "print(f\"Memory usage: {test_bank.memory_usage().sum() // 1024 ** 2} Mb\")\n",
    "\n",
    "del test_transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ba97bd",
   "metadata": {},
   "source": [
    "Now let's load clickstreaming service data and make train dataset at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c9e89c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 127/127 [02:41<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31955968, 4)\n",
      "Memory usage: 1219 Mb\n"
     ]
    }
   ],
   "source": [
    "def select_rtk_users_test(data): return data[data['user_id'].isin(test_rtk_users)]\n",
    "\n",
    "\n",
    "clicksreaming_test = Parallel(n_jobs=-1)(delayed(select_rtk_users_test)(\n",
    "    pd.read_parquet(f'click{i}.parquet', engine='fastparquet')) for i in trange(127))\n",
    "\n",
    "test_rtk = pd.concat(clicksreaming_test)\n",
    "print(test_rtk.shape)\n",
    "print(f\"Memory usage: {test_rtk.memory_usage().sum() // 1024 ** 2} Mb\")\n",
    "\n",
    "del clicksreaming_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5054c40f",
   "metadata": {},
   "source": [
    "Here it doesn't necessary to take a look at unique values, some random samples from the data because of structures of these data are similar to train ones.\n",
    "\n",
    "I'll start feature engineering at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe017933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (4952, 1855)\n",
      "Memory usage: 35 Mb\n",
      "------------------------------\n",
      "Shape: (4952, 342)\n",
      "Memory usage: 6 Mb\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bank_hours_test = make_hours_features(test_bank, time_col='transaction_dttm',\n",
    "                                       value_col='transaction_amt', prefix='bank')\n",
    "bank_embed_test = make_base_bank_features(test_bank)\n",
    "bank_embed_test = bank_embed_test.join(bank_hours_test)\n",
    "print(f'Shape: {bank_embed_test.shape}')\n",
    "print(f\"Memory usage: {bank_embed_test.memory_usage().sum() // 1024 ** 2} Mb\")\n",
    "\n",
    "print(30*'-')\n",
    "\n",
    "rtk_hours_test = make_hours_features(test_rtk, time_col='timestamp', value_col='timestamp', prefix='click')\n",
    "rtk_embed_test = make_base_rtk_features(test_rtk)\n",
    "rtk_embed_test = rtk_embed_test.join(rtk_hours_test)\n",
    "print(f'Shape: {rtk_embed_test.shape}')\n",
    "print(f\"Memory usage: {rtk_embed_test.memory_usage().sum() // 1024 ** 2} Mb\")\n",
    "\n",
    "del test_bank, test_rtk\n",
    "del bank_hours_test, rtk_hours_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d83d29d",
   "metadata": {},
   "source": [
    "After feature engineering there are 1855 features for transactions data and 342 features for clickstreaming service data.  \n",
    "During predicting matching it's necessary to put in order test data features because of inconsistent shapes of train and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff22e1dd",
   "metadata": {},
   "source": [
    "Let's create the base structure for test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7edb4bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_results = pd.DataFrame(columns=['bank'], data=test_bank_users)\n",
    "test_results['rtk'] = test_results['bank'].apply(lambda x: test_rtk_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe07fa6c",
   "metadata": {},
   "source": [
    "For test data batch size is 5. It'll help me to overcome memory issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9969845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "991"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "size = 5\n",
    "batches = int((len(test_bank_users))/size)+1\n",
    "batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3437aaac",
   "metadata": {},
   "source": [
    "So, let's predict matching for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ce71f67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 991/991 [1:49:23<00:00,  6.62s/it]\n"
     ]
    }
   ],
   "source": [
    "test_done = []\n",
    "for i in trange(batches):\n",
    "    \n",
    "    bank_test_indexes = test_bank_users[(i*size):((i+1)*size)]\n",
    "    \n",
    "    if len(bank_test_indexes) != 0:\n",
    "        \n",
    "        sub = test_results[test_results['bank'].isin(bank_test_indexes)].explode('rtk')\n",
    "        sub = sub.merge(bank_embed_test, how='left', left_on='bank', right_index=True)\\\n",
    "                 .merge(rtk_embed_test, how='left', left_on='rtk', right_index=True).fillna(0)\n",
    "           \n",
    "        for col in features:\n",
    "            if col not in sub.columns:\n",
    "                sub[col] = 0\n",
    "        \n",
    "        sub['predicts'] = model.predict_proba(sub[features])[:,1]\n",
    "        sub['predicts'] = sub['predicts'].astype('float32')\n",
    "        sub = sub[['bank', 'rtk', 'predicts']]\n",
    "        \n",
    "        sub = sub.sort_values(by=['bank', 'predicts'], ascending=False).reset_index(drop=True)\n",
    "        sub = sub.pivot_table(index='bank', values='rtk', aggfunc=list)\n",
    "        sub['rtk'] = sub['rtk'].apply(lambda x: x[:100])\n",
    "        sub['bank'] = sub.index\n",
    "        sub = sub[['bank', 'rtk']]\n",
    "        \n",
    "        test_done.append(sub)\n",
    "        \n",
    "del i, batches, size, col\n",
    "del bank_test_indexes, test_results, test\n",
    "del bank_embed_test, rtk_embed_test, sub\n",
    "del test_bank_users, test_rtk_users, features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e145f70",
   "metadata": {},
   "source": [
    "Let's concatenate all predictions and take a look at the first 5 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "91b1cb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 78.1 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>rtk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10f09bfecc7f4cf894897206d4020307</td>\n",
       "      <td>[2921476d7cf74afb9e05b45e476c591a, 4fc252276e6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>224a2325b44a4326bc539e3f1a6e713b</td>\n",
       "      <td>[8039a4b6372b40a490ff59bb1a4527c5, a60d6e61060...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6dd66e8624da427da6b558903a5772b8</td>\n",
       "      <td>[5858d3d01fe44ab1a9ecdd094d1093f4, f795f418fc1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8a1dd91a260143f4b6044da26844dde2</td>\n",
       "      <td>[48393d2085f345f4886eadd1243ad1b8, ec5e4863170...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ed547c635e594b88a9eb5b5f7ae75304</td>\n",
       "      <td>[4b6605d77c2b4fd28e3d8c3995a4e6fa, 38eb39dbd47...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               bank  \\\n",
       "0  10f09bfecc7f4cf894897206d4020307   \n",
       "1  224a2325b44a4326bc539e3f1a6e713b   \n",
       "2  6dd66e8624da427da6b558903a5772b8   \n",
       "3  8a1dd91a260143f4b6044da26844dde2   \n",
       "4  ed547c635e594b88a9eb5b5f7ae75304   \n",
       "\n",
       "                                                 rtk  \n",
       "0  [2921476d7cf74afb9e05b45e476c591a, 4fc252276e6...  \n",
       "1  [8039a4b6372b40a490ff59bb1a4527c5, a60d6e61060...  \n",
       "2  [5858d3d01fe44ab1a9ecdd094d1093f4, f795f418fc1...  \n",
       "3  [48393d2085f345f4886eadd1243ad1b8, ec5e4863170...  \n",
       "4  [4b6605d77c2b4fd28e3d8c3995a4e6fa, 38eb39dbd47...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "submission = pd.concat(test_done)\n",
    "submission.reset_index(inplace=True, drop=True)\n",
    "submission.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e13f35b",
   "metadata": {},
   "source": [
    "Finally let's make submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a999f293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 860 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "os.chdir(MAIN_PATH)\n",
    "\n",
    "submission.columns = ['bank', 'rtk_list']\n",
    "submission.to_csv(f'puzzle_sub.csv', index=False)\n",
    "\n",
    "del test_done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061930f9",
   "metadata": {},
   "source": [
    "I made 5 attempts to receive high score.\n",
    "\n",
    "My the best attempt has following scores:\n",
    "\n",
    "- [public]: 0.0213660899 (R1), 0.0116099809 (MRR@100), 0.1338063862 (Precision@100) (41 at leaderboard);\n",
    "- [private]: 0.0173880855 (R1), 0.0093427651 (MRR@100), 0.1252098019 (Precision@100) (41 at leaderboard)\n",
    "\n",
    "Drift relative to place at the leaderboard isn't but drawdown by scores is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dd56a0",
   "metadata": {},
   "source": [
    "----------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 281.844,
   "position": {
    "height": "303.844px",
    "left": "676px",
    "right": "20px",
    "top": "81px",
    "width": "678px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
