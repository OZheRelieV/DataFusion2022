{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd4a2fd1",
   "metadata": {},
   "source": [
    "# \"Education\" solution (DataFusion2022 track №3)¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf4f39a",
   "metadata": {},
   "source": [
    "For the first let's check available resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cb40a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: 2\n",
      "RAM 15.5 Gb\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from psutil import virtual_memory\n",
    "\n",
    "print(f\"CPU: {multiprocessing.cpu_count()}\")\n",
    "print(f\"RAM {round(virtual_memory().total / 1024**3, 1)} Gb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b250f727",
   "metadata": {},
   "source": [
    "There is one main data file:\n",
    "\n",
    "- transactions.csv, that can be fully put into RAM but in some transformation cases memory lack might be.\n",
    "\n",
    "That's why it was decided to provide an initial preprocessing. An initial preprocessing is splitting data file by 1_000_000 elements volume in each files and converting it into \".parquet\" extension.  \n",
    "So after it there are 20 files.  \n",
    "In this notebook I'll use these files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99690da3",
   "metadata": {},
   "source": [
    "## 0 Importing necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5854d03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import trange, tqdm\n",
    "from lightautoml.tasks import Task\n",
    "from joblib import Parallel, delayed\n",
    "from IPython.core.display import display\n",
    "from lightautoml.automl.presets.tabular_presets import TabularUtilizedAutoML\n",
    "\n",
    "tqdm.pandas()\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Initialising path for auxiliary files\n",
    "MAIN_PATH = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940eae1d",
   "metadata": {},
   "source": [
    "Let's create necessary functions for:\n",
    "\n",
    "- feature engineering;\n",
    "- feature transformation;\n",
    "- submission generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d39372e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_features(data):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is intended for feature engineering. Sum, mean and count features of\n",
    "    'mcc_code' are created taking in account all possible values of 'mcc_code'.\n",
    "    The function produces data type changing aiming to reduce usable memory usage and\n",
    "    prints new data shape and memory usage.\n",
    "    Input:\n",
    "    - data [pandas.DataFrame] - an initial data.\n",
    "    Output:\n",
    "    - data with new features [pandas.DataFrame].\n",
    "    \"\"\"\n",
    "        \n",
    "    df = data.pivot_table(index = 'user_id', values=['transaction_amt'], columns=['mcc_code'],\n",
    "                          aggfunc=['sum','mean', 'count']).fillna(0)\n",
    "    df.columns = [f'{i[0]}-{str(i[2])}' for i in df.columns]\n",
    "    \n",
    "    dtypes = [np.where('count' in col, 'int16', 'float32').tolist() for col in df.columns]   \n",
    "    dtypes = dict(zip(df.columns.tolist(), dtypes))\n",
    "    df = df.astype(dtypes)\n",
    "\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Memory usage: {df.memory_usage().sum() // 1024 ** 2} Mb\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebc722d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_count_features(data):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is intended for 'count' features binaziration. The main indicator of\n",
    "    binarization is Pearson correlation coefficient. If dummy feature has greater\n",
    "    correlation coefficient than the main feature then dummy feature will replace the main one.\n",
    "    Input:\n",
    "    - data [pandas.DataFrame] - an initial data.\n",
    "    Output:\n",
    "    - data with binarized 'count' features[pandas.DataFrame].\n",
    "    \"\"\"\n",
    "    \n",
    "    count_cols = [col for col in data.columns if 'count' in col]\n",
    "    print(f\"Total amount of 'count' features: {len(count_cols)}\")\n",
    "\n",
    "    columns = []\n",
    "    for idx, col in tqdm(enumerate(count_cols)):\n",
    "    \n",
    "        corr_ = np.abs(data.loc[:, [col, 'higher_education']].corr()['higher_education'][0])\n",
    "        data['dummy'] = np.where(data[col]>0, 1, 0)\n",
    "        dummy_corr = np.abs(data.loc[:, ['dummy', 'higher_education']].corr()['higher_education'][0])\n",
    "\n",
    "        if dummy_corr / corr_ > 1.0:\n",
    "\n",
    "            data[col] = data['dummy']\n",
    "            data[col] = data[col].astype('int8')\n",
    "            columns.append(col)\n",
    "        \n",
    "    data.drop(['dummy'], axis=1, inplace=True)\n",
    "\n",
    "    print(f\"Binarized: {len(columns)}\")\n",
    "    print(f\"Memory usage: {data.memory_usage().sum() // 1024 ** 2} Mb\")\n",
    "    \n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14d1f926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submit(data, predictions):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is intended for generating file with predictions.\n",
    "    The function prints first 10 samples of the submission data.\n",
    "    Input:\n",
    "    - data [pandas.DataFrame] - data with necessary indexes;\n",
    "    - predictions [list / numpy.array] - probability predictions.\n",
    "    Output:\n",
    "    - None.\n",
    "    \"\"\"\n",
    "    \n",
    "    submit = pd.DataFrame(columns=['bank'], data=data.index.to_list())\n",
    "    \n",
    "    submit['higher_education_proba'] = 0\n",
    "    submit['higher_education_proba'] = predictions\n",
    "    submit['higher_education_proba'] = submit['higher_education_proba'].astype('float64')\n",
    "    \n",
    "    display(submit.head(10))\n",
    "    \n",
    "    submit.to_csv('education_sub.csv', index=False)\n",
    "    \n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1710fb",
   "metadata": {},
   "source": [
    "## 1 Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eb20de",
   "metadata": {},
   "source": [
    "Let's load train data and create at once dictionary that contain \"user to education\" mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40d15eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8509\n",
      "Wall time: 53 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "he_train = pd.read_csv('train_education.csv')\n",
    "education_mapping = dict(zip(he_train['bank'].values, he_train['higher_education'].values))\n",
    "print(len(education_mapping))\n",
    "\n",
    "del he_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e47af3",
   "metadata": {},
   "source": [
    "Let's look at distribution of target variable - presence education fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c168ae77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(list(education_mapping.values()));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc81d593",
   "metadata": {},
   "source": [
    "There are about three times more users with higher education.   \n",
    "So, an imbalanced data are had to deal with "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2534186",
   "metadata": {},
   "source": [
    "So let's look through all files and filter data by function  \"select_bank_users_train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fbba776",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:32<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (7636113, 5)\n",
      "Memory usage: 349 Mb\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.join(MAIN_PATH, 'parquets'))\n",
    "\n",
    "\n",
    "def select_bank_users_train(data): return data[data['user_id'].isin(list(education_mapping.keys()))]\n",
    "\n",
    "\n",
    "train_transactions = Parallel(n_jobs=-1)(delayed(select_bank_users_train)(\n",
    "    pd.read_parquet(f'bank{i}.parquet', engine='fastparquet')) for i in trange(20))\n",
    "df_train = pd.concat(train_transactions)\n",
    "\n",
    "print(f\"Shape: {df_train.shape}\")\n",
    "print(f\"Memory usage: {df_train.memory_usage().sum() // 1024 ** 2} Mb\")\n",
    "\n",
    "del train_transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf280531",
   "metadata": {},
   "source": [
    "Let's check amount of 'mcc_code' unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72a63887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354\n",
      "Wall time: 117 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(df_train['mcc_code'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a889a8",
   "metadata": {},
   "source": [
    "'mcc_code' values of train data is less than total 'mcc_code' values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb977110",
   "metadata": {},
   "source": [
    "Now it's necessary to load data with test users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0c0029d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of unique users: 4000\n",
      "Wall time: 44 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "os.chdir(MAIN_PATH)\n",
    "\n",
    "test_users = pd.read_csv('sample_submission_education.csv', usecols=['bank'])['bank'].unique()\n",
    "print(f\"Amount of unique users: {len(test_users)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a66b19c",
   "metadata": {},
   "source": [
    "So let's look through all files and filter data by function \"select_bank_users_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4153bf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:24<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (3626427, 5)\n",
      "Memory usage: 166 Mb\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.join(MAIN_PATH, 'parquets'))\n",
    "\n",
    "\n",
    "def select_bank_users_test(data): return data[data['user_id'].isin(test_users)]\n",
    "\n",
    "\n",
    "test_transactions = Parallel(n_jobs=-1)(delayed(select_bank_users_test)(\n",
    "    pd.read_parquet(f'bank{i}.parquet', engine='fastparquet')) for i in trange(20))\n",
    "df_test = pd.concat(test_transactions)\n",
    "\n",
    "print(f\"Shape: {df_test.shape}\")\n",
    "print(f\"Memory usage: {df_test.memory_usage().sum() // 1024 ** 2} Mb\")\n",
    "\n",
    "del test_users, test_transactions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67174151",
   "metadata": {},
   "source": [
    "Let's check amount of 'mcc_code' unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48f5634f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325\n",
      "Wall time: 68 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(df_test['mcc_code'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a1ae90",
   "metadata": {},
   "source": [
    "There are fewer transaction codes in the test data than in the train one.  \n",
    "I'll use only those transactions that are in both data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f520ea",
   "metadata": {},
   "source": [
    "Let's select data by 'mcc_code' values that are in both data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13aecbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "selected_mcc = list(set(df_train['mcc_code'].unique()).intersection(set(df_test['mcc_code'].unique())))\n",
    "\n",
    "df_train = df_train[df_train['mcc_code'].isin(selected_mcc)]\n",
    "df_test = df_test[df_test['mcc_code'].isin(selected_mcc)]\n",
    "\n",
    "assert df_train['mcc_code'].nunique() == df_test['mcc_code'].nunique(), 'Количество \"mcc_codes\" не сходится...'\n",
    "\n",
    "del selected_mcc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45fa1e6",
   "metadata": {},
   "source": [
    "This selection will allow me to receive processed data with the same amount features in both data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27b8da0",
   "metadata": {},
   "source": [
    "## 2 Feature engineering and it transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b501f2d9",
   "metadata": {},
   "source": [
    "It's time to generate new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b545892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (8509, 942)\n",
      "Memory usage: 25 Mb\n",
      "--------------------\n",
      "Shape: (4000, 942)\n",
      "Memory usage: 12 Mb\n",
      "Wall time: 14.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_train = gen_features(df_train)\n",
    "print(20*'-')\n",
    "df_test = gen_features(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779c9514",
   "metadata": {},
   "source": [
    "Let's set target values for train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e67bbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 8509/8509 [00:00<00:00, 656621.21it/s]\n"
     ]
    }
   ],
   "source": [
    "df_train['higher_education'] = [education_mapping[idx] for idx in tqdm(df_train.index)]\n",
    "\n",
    "del education_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3600e7",
   "metadata": {},
   "source": [
    "It was found that binaziration of 'count' features allow to increase score. So let's produce this operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28d4d03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total amount of 'count' features: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "314it [00:03, 85.11it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binarized: 241\n",
      "Memory usage: 23 Mb\n",
      "Memory usage: 11 Mb\n"
     ]
    }
   ],
   "source": [
    "get_dummies = binarize_count_features(df_train)\n",
    "\n",
    "for col in get_dummies:\n",
    "    df_test[col] = np.where(df_test[col]>0, 1, 0)\n",
    "    df_test[col] = df_test[col].astype('int8')\n",
    "print(f\"Memory usage: {df_test.memory_usage().sum() // 1024 ** 2} Mb\")\n",
    "\n",
    "del get_dummies, col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f71f4dd",
   "metadata": {},
   "source": [
    "Our data is ready to auto machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12485de",
   "metadata": {},
   "source": [
    "## 3 Auto machine learning (LightAutoML)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8a407f",
   "metadata": {},
   "source": [
    "In this track I tried to apply auto machine learning approach.  \n",
    "I used lightautoml from SberAI.\n",
    "\n",
    "Time of auto machine learning was set to 2 hours in hope to receive high scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4f1d11a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:58:26] Start automl \u001b[1mutilizator\u001b[0m with listed constraints:\n",
      "[19:58:26] - time: 7200.00 seconds\n",
      "[19:58:26] - CPU: 2 cores\n",
      "[19:58:26] - memory: 16 GB\n",
      "\n",
      "[19:58:26] \u001b[1mIf one preset completes earlier, next preset configuration will be started\u001b[0m\n",
      "\n",
      "[19:58:26] ==================================================\n",
      "[19:58:26] Start 0 automl preset configuration:\n",
      "[19:58:26] \u001b[1mC:\\Users\\ozher\\anaconda3\\envs\\MyEnv\\lib\\site-packages\\lightautoml\\automl\\presets\\tabular_configs\\conf_0_sel_type_0.yml\u001b[0m, random state: {'reader_params': {'random_state': 42}, 'general_params': {'return_all_predictions': False}}\n",
      "[19:58:26] Stdout logging level is INFO.\n",
      "[19:58:26] Task: binary\n",
      "\n",
      "[19:58:26] Start automl preset with listed constraints:\n",
      "[19:58:26] - time: 7199.98 seconds\n",
      "[19:58:26] - CPU: 2 cores\n",
      "[19:58:26] - memory: 16 GB\n",
      "\n",
      "[19:58:26] \u001b[1mTrain data shape: (8509, 943)\u001b[0m\n",
      "\n",
      "[19:58:57] Layer \u001b[1m1\u001b[0m train process start. Time left 7169.69 secs\n",
      "[19:58:58] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[19:59:07] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.788679907691018\u001b[0m\n",
      "[19:59:07] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[19:59:07] Time left 7159.23 secs\n",
      "\n",
      "[19:59:08] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[20:04:19] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.7941257738236283\u001b[0m\n",
      "[20:04:19] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[20:04:19] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[20:04:19] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[20:09:27] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[20:09:27] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[20:15:29] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.7840952019718921\u001b[0m\n",
      "[20:15:29] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[20:15:30] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[20:17:57] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.7909715516200343\u001b[0m\n",
      "[20:17:57] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[20:17:57] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[20:23:11] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[20:23:11] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[20:25:36] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.7881112416465503\u001b[0m\n",
      "[20:25:36] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[20:25:36] Time left 5569.85 secs\n",
      "\n",
      "[20:25:36] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[20:25:36] Blending: optimization starts with equal weights and score \u001b[1m0.7971727573137772\u001b[0m\n",
      "[20:25:37] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7979526500792135\u001b[0m, weights = \u001b[1m[0.38340092 0.36095378 0.09319688 0.05751076 0.10493769]\u001b[0m\n",
      "[20:25:37] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.7979539641943734\u001b[0m, weights = \u001b[1m[0.38190335 0.36173442 0.09356248 0.05763514 0.10516464]\u001b[0m\n",
      "[20:25:37] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.7979539641943734\u001b[0m, weights = \u001b[1m[0.38190335 0.36173442 0.09356248 0.05763514 0.10516464]\u001b[0m\n",
      "[20:25:37] Blending: no score update. Terminated\n",
      "\n",
      "[20:25:37] \u001b[1mAutoml preset training completed in 1631.01 seconds\u001b[0m\n",
      "\n",
      "[20:25:37] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.38190 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.36173 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.09356 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.05764 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.10516 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[20:25:37] ==================================================\n",
      "[20:25:37] Start 1 automl preset configuration:\n",
      "[20:25:37] \u001b[1mC:\\Users\\ozher\\anaconda3\\envs\\MyEnv\\lib\\site-packages\\lightautoml\\automl\\presets\\tabular_configs\\conf_1_sel_type_1.yml\u001b[0m, random state: {'reader_params': {'random_state': 43}, 'general_params': {'return_all_predictions': False}}\n",
      "[20:25:37] Stdout logging level is INFO.\n",
      "[20:25:37] Task: binary\n",
      "\n",
      "[20:25:37] Start automl preset with listed constraints:\n",
      "[20:25:37] - time: 5568.85 seconds\n",
      "[20:25:37] - CPU: 2 cores\n",
      "[20:25:37] - memory: 16 GB\n",
      "\n",
      "[20:25:37] \u001b[1mTrain data shape: (8509, 943)\u001b[0m\n",
      "\n",
      "[20:26:10] Layer \u001b[1m1\u001b[0m train process start. Time left 5536.01 secs\n",
      "[20:26:12] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[20:26:27] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7916418540975286\u001b[0m\n",
      "[20:26:27] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[20:26:27] Time left 5518.72 secs\n",
      "\n",
      "[20:29:17] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[20:29:18] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[20:35:23] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.7922366641172833\u001b[0m\n",
      "[20:35:23] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[20:35:23] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 1.00 secs\n",
      "[20:41:25] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[20:41:25] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[20:47:07] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.7924944727624734\u001b[0m\n",
      "[20:47:07] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[20:47:07] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[20:48:41] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.7945368843768169\u001b[0m\n",
      "[20:48:41] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[20:48:41] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[20:53:49] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[20:53:49] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[20:55:20] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.7948550385734298\u001b[0m\n",
      "[20:55:21] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[20:55:21] Time left 3785.66 secs\n",
      "\n",
      "[20:55:21] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[20:55:21] Blending: optimization starts with equal weights and score \u001b[1m0.8000209635949986\u001b[0m\n",
      "[20:55:21] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8006713122712489\u001b[0m, weights = \u001b[1m[0.38889652 0.0716003  0.1637235  0.22013251 0.15564714]\u001b[0m\n",
      "[20:55:21] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8006762574940876\u001b[0m, weights = \u001b[1m[0.40881822 0.07526811 0.17211042 0.18018289 0.16362035]\u001b[0m\n",
      "[20:55:21] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8006989778535631\u001b[0m, weights = \u001b[1m[0.4116321  0.         0.18050697 0.20463808 0.20322287]\u001b[0m\n",
      "[20:55:22] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8007015023379492\u001b[0m, weights = \u001b[1m[0.4282177  0.         0.18778004 0.17091553 0.21308675]\u001b[0m\n",
      "[20:55:22] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m0.8007045455520039\u001b[0m, weights = \u001b[1m[0.42529374 0.         0.18649784 0.1765766  0.21163176]\u001b[0m\n",
      "[20:55:22] \u001b[1mAutoml preset training completed in 1784.52 seconds\u001b[0m\n",
      "\n",
      "[20:55:22] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.42529 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.18650 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.17658 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.21163 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[20:55:22] ==================================================\n",
      "[20:55:22] Start 2 automl preset configuration:\n",
      "[20:55:22] \u001b[1mC:\\Users\\ozher\\anaconda3\\envs\\MyEnv\\lib\\site-packages\\lightautoml\\automl\\presets\\tabular_configs\\conf_2_select_mode_1_no_typ.yml\u001b[0m, random state: {'reader_params': {'random_state': 44}, 'general_params': {'return_all_predictions': False}}\n",
      "[20:55:22] Stdout logging level is INFO.\n",
      "[20:55:22] Task: binary\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:55:22] Start automl preset with listed constraints:\n",
      "[20:55:22] - time: 3784.28 seconds\n",
      "[20:55:22] - CPU: 2 cores\n",
      "[20:55:22] - memory: 16 GB\n",
      "\n",
      "[20:55:22] \u001b[1mTrain data shape: (8509, 943)\u001b[0m\n",
      "\n",
      "[20:55:23] Layer \u001b[1m1\u001b[0m train process start. Time left 3782.74 secs\n",
      "[20:55:25] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[20:55:33] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7903307475696824\u001b[0m\n",
      "[20:55:33] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[20:55:33] Time left 3773.39 secs\n",
      "\n",
      "[20:56:49] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[20:56:50] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[21:01:58] Time limit exceeded after calculating fold 3\n",
      "\n",
      "[21:01:58] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.7950342321263052\u001b[0m\n",
      "[21:01:58] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[21:01:58] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 1.00 secs\n",
      "[21:06:09] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[21:06:09] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[21:11:21] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.7872559601693078\u001b[0m\n",
      "[21:11:21] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[21:11:21] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[21:12:27] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.7909468600878189\u001b[0m\n",
      "[21:12:27] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[21:12:27] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[21:17:34] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[21:17:34] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[21:18:56] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.794024033644668\u001b[0m\n",
      "[21:18:56] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[21:18:56] Time left 2369.95 secs\n",
      "\n",
      "[21:18:56] Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n",
      "[21:18:56] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[21:18:56] Blending: optimization starts with equal weights and score \u001b[1m0.7997250456101707\u001b[0m\n",
      "[21:18:57] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8005636585740687\u001b[0m, weights = \u001b[1m[0.34131688 0.24202637 0.251657   0.         0.1649998 ]\u001b[0m\n",
      "[21:18:57] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8006481423460607\u001b[0m, weights = \u001b[1m[0.3960213  0.21346055 0.2397675  0.         0.15075067]\u001b[0m\n",
      "[21:18:57] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8006499406089111\u001b[0m, weights = \u001b[1m[0.40083823 0.20389359 0.24268386 0.         0.15258428]\u001b[0m\n",
      "[21:18:57] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8006499406089111\u001b[0m, weights = \u001b[1m[0.40083823 0.20389359 0.24268386 0.         0.15258428]\u001b[0m\n",
      "[21:18:57] Blending: no score update. Terminated\n",
      "\n",
      "[21:18:57] \u001b[1mAutoml preset training completed in 1415.56 seconds\u001b[0m\n",
      "\n",
      "[21:18:57] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.40084 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.20389 * (4 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.24268 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.15258 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[21:18:57] ==================================================\n",
      "[21:18:57] Start 3 automl preset configuration:\n",
      "[21:18:57] \u001b[1mC:\\Users\\ozher\\anaconda3\\envs\\MyEnv\\lib\\site-packages\\lightautoml\\automl\\presets\\tabular_configs\\conf_3_sel_type_1_no_inter_lgbm.yml\u001b[0m, random state: {'reader_params': {'random_state': 45}, 'general_params': {'return_all_predictions': False}}\n",
      "[21:18:57] Stdout logging level is INFO.\n",
      "[21:18:57] Task: binary\n",
      "\n",
      "[21:18:57] Start automl preset with listed constraints:\n",
      "[21:18:57] - time: 2368.66 seconds\n",
      "[21:18:57] - CPU: 2 cores\n",
      "[21:18:57] - memory: 16 GB\n",
      "\n",
      "[21:18:57] \u001b[1mTrain data shape: (8509, 943)\u001b[0m\n",
      "\n",
      "[21:19:28] Layer \u001b[1m1\u001b[0m train process start. Time left 2337.68 secs\n",
      "[21:19:31] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[21:19:39] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7890815427822641\u001b[0m\n",
      "[21:19:39] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[21:19:39] Time left 2327.46 secs\n",
      "\n",
      "[21:20:58] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[21:20:59] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[21:24:41] Time limit exceeded after calculating fold 2\n",
      "\n",
      "[21:24:41] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.7891502592087261\u001b[0m\n",
      "[21:24:41] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[21:24:41] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 1.00 secs\n",
      "[21:28:42] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[21:28:43] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[21:29:58] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.7913199650473033\u001b[0m\n",
      "[21:29:58] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[21:29:58] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 300.00 secs\n",
      "[21:35:08] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[21:35:08] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[21:36:27] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.7915470303141467\u001b[0m\n",
      "[21:36:27] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[21:36:27] Time left 1319.65 secs\n",
      "\n",
      "[21:36:27] Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n",
      "[21:36:27] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[21:36:27] Blending: optimization starts with equal weights and score \u001b[1m0.796102998409644\u001b[0m\n",
      "[21:36:27] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7963809683479457\u001b[0m, weights = \u001b[1m[0.3927001  0.14262629 0.21722057 0.24745305]\u001b[0m\n",
      "[21:36:27] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.796403723289399\u001b[0m, weights = \u001b[1m[0.36913568 0.14673229 0.22955522 0.25457686]\u001b[0m\n",
      "[21:36:27] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.7964073889790556\u001b[0m, weights = \u001b[1m[0.36688894 0.14657283 0.23161975 0.25491852]\u001b[0m\n",
      "[21:36:28] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.7964071123232325\u001b[0m, weights = \u001b[1m[0.36688894 0.14657283 0.23161975 0.25491852]\u001b[0m\n",
      "[21:36:28] Blending: no score update. Terminated\n",
      "\n",
      "[21:36:28] \u001b[1mAutoml preset training completed in 1050.16 seconds\u001b[0m\n",
      "\n",
      "[21:36:28] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.36689 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.14657 * (3 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.23162 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.25492 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[21:36:28] ==================================================\n",
      "[21:36:28] Blending: optimization starts with equal weights and score \u001b[1m0.8010257083806934\u001b[0m\n",
      "[21:36:28] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.801924113584368\u001b[0m, weights = \u001b[1m[0.         0.43519568 0.5648043  0.        ]\u001b[0m\n",
      "[21:36:28] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8019467993618657\u001b[0m, weights = \u001b[1m[0.         0.5058721  0.49412796 0.        ]\u001b[0m\n",
      "[21:36:28] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8019467993618657\u001b[0m, weights = \u001b[1m[0.         0.5058721  0.49412796 0.        ]\u001b[0m\n",
      "[21:36:28] Blending: no score update. Terminated\n",
      "\n"
     ]
    }
   ],
   "source": [
    "automl = TabularUtilizedAutoML(\n",
    "    task=Task('binary', loss='logloss', metric='auc'),\n",
    "    timeout=7200,\n",
    "    cpu_limit=2,\n",
    "    reader_params={'n_jobs': 2, 'cv': 5, 'random_state': 42, 'verbose': 1}\n",
    ")\n",
    "\n",
    "oof_pred = automl.fit_predict(\n",
    "    df_train,\n",
    "    roles={'target': 'higher_education'},\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906bc3fd",
   "metadata": {},
   "source": [
    "It's time to make probability predictions for test users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9980d166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "Wall time: 15.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prob_preds = automl.predict(df_test).data\n",
    "print(len(prob_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c35d313",
   "metadata": {},
   "source": [
    "## 4 Submit generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d33cbb",
   "metadata": {},
   "source": [
    "Let's create submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a0c3634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank</th>\n",
       "      <th>higher_education_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000e0d54d7c945ebb8f6f855972e8396</td>\n",
       "      <td>0.575523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001708a5fca04c2ca58d7188b747d5f5</td>\n",
       "      <td>0.887440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001c99d8cd6f409f87986b8fba8aa092</td>\n",
       "      <td>0.928007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0020536c52ee4257b4619dea899a0cf6</td>\n",
       "      <td>0.692040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>003d93fb918846ada33fa3977af878eb</td>\n",
       "      <td>0.349857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0047dbb5ef764871af8874814ad3be87</td>\n",
       "      <td>0.794621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00491339a09c4638a0f27ca51f615d67</td>\n",
       "      <td>0.413134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0049c761c1e6468fb6df389dba900ebe</td>\n",
       "      <td>0.483120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0056f6f484c543f49cb434c064b5d85a</td>\n",
       "      <td>0.834504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>006415c4240844e0810617ecebbd2db4</td>\n",
       "      <td>0.396748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               bank  higher_education_proba\n",
       "0  000e0d54d7c945ebb8f6f855972e8396                0.575523\n",
       "1  001708a5fca04c2ca58d7188b747d5f5                0.887440\n",
       "2  001c99d8cd6f409f87986b8fba8aa092                0.928007\n",
       "3  0020536c52ee4257b4619dea899a0cf6                0.692040\n",
       "4  003d93fb918846ada33fa3977af878eb                0.349857\n",
       "5  0047dbb5ef764871af8874814ad3be87                0.794621\n",
       "6  00491339a09c4638a0f27ca51f615d67                0.413134\n",
       "7  0049c761c1e6468fb6df389dba900ebe                0.483120\n",
       "8  0056f6f484c543f49cb434c064b5d85a                0.834504\n",
       "9  006415c4240844e0810617ecebbd2db4                0.396748"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "os.chdir(MAIN_PATH)\n",
    "\n",
    "make_submit(df_test, prob_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72426642",
   "metadata": {},
   "source": [
    "I made a great amount of attempts to receive high score.\n",
    "\n",
    "My the best attempt has following scores:\n",
    "\n",
    "- [public]: 0.790160 (roc_auc) (33 at leaderboard);\n",
    "- [private]: 0.785577 (roc_auc) (39 at leaderboard)\n",
    "\n",
    "There were drift relative to place at the leaderboard and drawdown by scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2821abf0",
   "metadata": {},
   "source": [
    "----------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 223.844,
   "position": {
    "height": "40px",
    "left": "721px",
    "right": "20px",
    "top": "75px",
    "width": "645px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
